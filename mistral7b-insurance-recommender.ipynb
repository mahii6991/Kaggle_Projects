{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12216995,"sourceType":"datasetVersion","datasetId":7696685}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:49:45.290883Z","iopub.execute_input":"2025-06-19T19:49:45.291073Z","iopub.status.idle":"2025-06-19T19:49:47.169915Z","shell.execute_reply.started":"2025-06-19T19:49:45.291051Z","shell.execute_reply":"2025-06-19T19:49:47.169358Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/insurance-companies/data_V3.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:49:47.171016Z","iopub.execute_input":"2025-06-19T19:49:47.171433Z","iopub.status.idle":"2025-06-19T19:49:47.576564Z","shell.execute_reply.started":"2025-06-19T19:49:47.171413Z","shell.execute_reply":"2025-06-19T19:49:47.575949Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:49:47.577383Z","iopub.execute_input":"2025-06-19T19:49:47.577678Z","iopub.status.idle":"2025-06-19T19:49:47.583669Z","shell.execute_reply.started":"2025-06-19T19:49:47.577635Z","shell.execute_reply":"2025-06-19T19:49:47.582976Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(33501, 28)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:49:47.584367Z","iopub.execute_input":"2025-06-19T19:49:47.584581Z","iopub.status.idle":"2025-06-19T19:49:47.628046Z","shell.execute_reply.started":"2025-06-19T19:49:47.584564Z","shell.execute_reply":"2025-06-19T19:49:47.627380Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  Claim Ref   UCR / Claim Ref Gemini Instruction Ref  \\\n0  CLA/9599  0901L91936863003            Instr-12479   \n1  CLA/9599  0901L91936863003            Instr-12479   \n2  CLA/9599  0901L91936863003            Instr-12479   \n3  CLA/9599  0901L91936863003            Instr-12479   \n4  CLA/9599  0901L91936863003            Instr-12479   \n\n                  Company Name  Gemini Invoice Ref Gemini Invoice Ref.1  \\\n0  Reynolds Porter Chamberlain             1038794         G05241038794   \n1  Reynolds Porter Chamberlain             1038793         G05241038793   \n2  Reynolds Porter Chamberlain             1038792         G05241038792   \n3  Reynolds Porter Chamberlain             1038791         G05241038791   \n4  Reynolds Porter Chamberlain             1038790         G05241038790   \n\n  Expert Invoice Ref Expert Invoice Ref.1  \\\n0            4081271              4081271   \n1            4082764              4082764   \n2                  -                    -   \n3            4074845              4074845   \n4            4079608              4079608   \n\n           Expert User: Expert Name and Organisation MC Recipient ID  ...  \\\n0  Lauren Crockett (Reynolds Porter Chamberlain -...         1737270  ...   \n1  Lauren Crockett (Reynolds Porter Chamberlain -...         1737270  ...   \n2  Lauren Crockett (Reynolds Porter Chamberlain -...               -  ...   \n3  Lauren Crockett (Reynolds Porter Chamberlain -...         1737270  ...   \n4  Lauren Crockett (Reynolds Porter Chamberlain -...         1737270  ...   \n\n  Payment Date Invoice Paid Date and time             Status Choice  \\\n0            -                          -  Submitted for Validation   \n1            -                          -  Submitted for Validation   \n2            -                          -                     Draft   \n3            -                          -  Submitted for Validation   \n4            -                          -  Submitted for Validation   \n\n  Total Invoice Amount ISO Code This is how much we paid Percentage we paid  \\\n0             2,023.42      GBP                 1,618.74             80.00%   \n1             1,096.13      GBP                    876.9             80.00%   \n2                    -        -                        0             80.00%   \n3               211.82      GBP                   169.46             80.00%   \n4             2,160.05      GBP                 1,728.04             80.00%   \n\n                               Insurer                       Expert  \\\n0  Chubb Underwriting Agencies Limited  Reynolds Porter Chamberlain   \n1  Chubb Underwriting Agencies Limited  Reynolds Porter Chamberlain   \n2  Chubb Underwriting Agencies Limited  Reynolds Porter Chamberlain   \n3  Chubb Underwriting Agencies Limited  Reynolds Porter Chamberlain   \n4  Chubb Underwriting Agencies Limited  Reynolds Porter Chamberlain   \n\n  Claim Class of Business  \n0         Casualty FinPro  \n1         Casualty FinPro  \n2         Casualty FinPro  \n3         Casualty FinPro  \n4         Casualty FinPro  \n\n[5 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Claim Ref</th>\n      <th>UCR / Claim Ref</th>\n      <th>Gemini Instruction Ref</th>\n      <th>Company Name</th>\n      <th>Gemini Invoice Ref</th>\n      <th>Gemini Invoice Ref.1</th>\n      <th>Expert Invoice Ref</th>\n      <th>Expert Invoice Ref.1</th>\n      <th>Expert User: Expert Name and Organisation</th>\n      <th>MC Recipient ID</th>\n      <th>...</th>\n      <th>Payment Date</th>\n      <th>Invoice Paid Date and time</th>\n      <th>Status Choice</th>\n      <th>Total Invoice Amount</th>\n      <th>ISO Code</th>\n      <th>This is how much we paid</th>\n      <th>Percentage we paid</th>\n      <th>Insurer</th>\n      <th>Expert</th>\n      <th>Claim Class of Business</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CLA/9599</td>\n      <td>0901L91936863003</td>\n      <td>Instr-12479</td>\n      <td>Reynolds Porter Chamberlain</td>\n      <td>1038794</td>\n      <td>G05241038794</td>\n      <td>4081271</td>\n      <td>4081271</td>\n      <td>Lauren Crockett (Reynolds Porter Chamberlain -...</td>\n      <td>1737270</td>\n      <td>...</td>\n      <td>-</td>\n      <td>-</td>\n      <td>Submitted for Validation</td>\n      <td>2,023.42</td>\n      <td>GBP</td>\n      <td>1,618.74</td>\n      <td>80.00%</td>\n      <td>Chubb Underwriting Agencies Limited</td>\n      <td>Reynolds Porter Chamberlain</td>\n      <td>Casualty FinPro</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CLA/9599</td>\n      <td>0901L91936863003</td>\n      <td>Instr-12479</td>\n      <td>Reynolds Porter Chamberlain</td>\n      <td>1038793</td>\n      <td>G05241038793</td>\n      <td>4082764</td>\n      <td>4082764</td>\n      <td>Lauren Crockett (Reynolds Porter Chamberlain -...</td>\n      <td>1737270</td>\n      <td>...</td>\n      <td>-</td>\n      <td>-</td>\n      <td>Submitted for Validation</td>\n      <td>1,096.13</td>\n      <td>GBP</td>\n      <td>876.9</td>\n      <td>80.00%</td>\n      <td>Chubb Underwriting Agencies Limited</td>\n      <td>Reynolds Porter Chamberlain</td>\n      <td>Casualty FinPro</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CLA/9599</td>\n      <td>0901L91936863003</td>\n      <td>Instr-12479</td>\n      <td>Reynolds Porter Chamberlain</td>\n      <td>1038792</td>\n      <td>G05241038792</td>\n      <td>-</td>\n      <td>-</td>\n      <td>Lauren Crockett (Reynolds Porter Chamberlain -...</td>\n      <td>-</td>\n      <td>...</td>\n      <td>-</td>\n      <td>-</td>\n      <td>Draft</td>\n      <td>-</td>\n      <td>-</td>\n      <td>0</td>\n      <td>80.00%</td>\n      <td>Chubb Underwriting Agencies Limited</td>\n      <td>Reynolds Porter Chamberlain</td>\n      <td>Casualty FinPro</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CLA/9599</td>\n      <td>0901L91936863003</td>\n      <td>Instr-12479</td>\n      <td>Reynolds Porter Chamberlain</td>\n      <td>1038791</td>\n      <td>G05241038791</td>\n      <td>4074845</td>\n      <td>4074845</td>\n      <td>Lauren Crockett (Reynolds Porter Chamberlain -...</td>\n      <td>1737270</td>\n      <td>...</td>\n      <td>-</td>\n      <td>-</td>\n      <td>Submitted for Validation</td>\n      <td>211.82</td>\n      <td>GBP</td>\n      <td>169.46</td>\n      <td>80.00%</td>\n      <td>Chubb Underwriting Agencies Limited</td>\n      <td>Reynolds Porter Chamberlain</td>\n      <td>Casualty FinPro</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CLA/9599</td>\n      <td>0901L91936863003</td>\n      <td>Instr-12479</td>\n      <td>Reynolds Porter Chamberlain</td>\n      <td>1038790</td>\n      <td>G05241038790</td>\n      <td>4079608</td>\n      <td>4079608</td>\n      <td>Lauren Crockett (Reynolds Porter Chamberlain -...</td>\n      <td>1737270</td>\n      <td>...</td>\n      <td>-</td>\n      <td>-</td>\n      <td>Submitted for Validation</td>\n      <td>2,160.05</td>\n      <td>GBP</td>\n      <td>1,728.04</td>\n      <td>80.00%</td>\n      <td>Chubb Underwriting Agencies Limited</td>\n      <td>Reynolds Porter Chamberlain</td>\n      <td>Casualty FinPro</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:49:47.629791Z","iopub.execute_input":"2025-06-19T19:49:47.630454Z","iopub.status.idle":"2025-06-19T19:49:47.636099Z","shell.execute_reply.started":"2025-06-19T19:49:47.630434Z","shell.execute_reply":"2025-06-19T19:49:47.635569Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Index(['Claim Ref', 'UCR / Claim Ref', 'Gemini Instruction Ref',\n       'Company Name', 'Gemini Invoice Ref', 'Gemini Invoice Ref.1',\n       'Expert Invoice Ref', 'Expert Invoice Ref.1',\n       'Expert User: Expert Name and Organisation', 'MC Recipient ID',\n       'Bank Account Name', 'Currency', 'Date submitted', 'Date created',\n       'Time Taken since submission', 'Ecliptic Approval Timer',\n       'Carrier Approval Timer', 'Payment Approval Timer', 'Payment Date',\n       'Invoice Paid Date and time', 'Status Choice', 'Total Invoice Amount',\n       'ISO Code', 'This is how much we paid', 'Percentage we paid', 'Insurer',\n       'Expert', 'Claim Class of Business'],\n      dtype='object')"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:49:47.636708Z","iopub.execute_input":"2025-06-19T19:49:47.636902Z","iopub.status.idle":"2025-06-19T19:49:47.698302Z","shell.execute_reply.started":"2025-06-19T19:49:47.636886Z","shell.execute_reply":"2025-06-19T19:49:47.697637Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Claim Ref                                    0\nUCR / Claim Ref                              0\nGemini Instruction Ref                       0\nCompany Name                                 0\nGemini Invoice Ref                           0\nGemini Invoice Ref.1                         0\nExpert Invoice Ref                           0\nExpert Invoice Ref.1                         0\nExpert User: Expert Name and Organisation    0\nMC Recipient ID                              0\nBank Account Name                            0\nCurrency                                     0\nDate submitted                               0\nDate created                                 0\nTime Taken since submission                  0\nEcliptic Approval Timer                      0\nCarrier Approval Timer                       0\nPayment Approval Timer                       0\nPayment Date                                 0\nInvoice Paid Date and time                   0\nStatus Choice                                0\nTotal Invoice Amount                         0\nISO Code                                     0\nThis is how much we paid                     0\nPercentage we paid                           0\nInsurer                                      0\nExpert                                       0\nClaim Class of Business                      0\ndtype: int64"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"pip install -q transformers torch bitsandbytes accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:49:47.698869Z","iopub.execute_input":"2025-06-19T19:49:47.699081Z","iopub.status.idle":"2025-06-19T19:51:02.364904Z","shell.execute_reply.started":"2025-06-19T19:49:47.699054Z","shell.execute_reply":"2025-06-19T19:51:02.364073Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"pip install -q -U bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:51:02.365843Z","iopub.execute_input":"2025-06-19T19:51:02.366097Z","iopub.status.idle":"2025-06-19T19:51:05.610140Z","shell.execute_reply.started":"2025-06-19T19:51:02.366067Z","shell.execute_reply":"2025-06-19T19:51:05.609085Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nimport torch\n\n# Set the device\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")\n\n# --- Quantization Configuration ---\n# Load the model in 4-bit precision using BitsAndBytesConfig\n# This significantly reduces memory usage.\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,             # Load model weights in 4-bit\n    bnb_4bit_use_double_quant=True, # Use double quantization for better memory savings\n    bnb_4bit_quant_type=\"nf4\",      # Use the NF4 quantization type (recommended for transformers)\n    bnb_4bit_compute_dtype=torch.bfloat16 # Use bfloat16 for computations (if your GPU supports it, generally RTX 30 series and newer)\n    # Or torch.float16 if bfloat16 is not supported or causes issues\n    # bnb_4bit_compute_dtype=torch.float16\n)\n\n# --- Load Model with Quantization ---\n# The quantization_config argument tells transformers to load the model using the bnb config\n# We also specify torch_dtype to ensure computations are done in a lower precision\n# Adding device_map='auto' tells accelerate to automatically place model parts (useful with bnb)\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"bitext/Mistral-7B-Insurance\",\n    quantization_config=bnb_config,\n    torch_dtype=torch.bfloat16, # Or torch.float16\n    device_map='auto' # Automatically determines where to place model layers (usually GPU with bnb)\n)\n\n# --- Load Tokenizer ---\n# Tokenizers are small and don't require special memory handling\ntokenizer = AutoTokenizer.from_pretrained(\"bitext/Mistral-7B-Insurance\")\n\n# Note: With device_map='auto' and bnb quantization, the model is usually\n# loaded directly onto the GPU in a sharded way if needed.\n# Calling model.to(device) might be redundant but is generally harmless\n# unless you have multiple GPUs and need to force it to a specific one.\n# The 'device_map='auto'' handles this for you.\n\nprint(\"Model and Tokenizer loaded successfully!\")\n# You can now proceed with inference, e.g.,\n# inputs = tokenizer(\"Your prompt here\", return_tensors=\"pt\").to(device)\n# outputs = model.generate(**inputs)\n# print(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:51:05.611360Z","iopub.execute_input":"2025-06-19T19:51:05.611647Z","iopub.status.idle":"2025-06-19T19:52:54.304755Z","shell.execute_reply.started":"2025-06-19T19:51:05.611609Z","shell.execute_reply":"2025-06-19T19:52:54.304062Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/673 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"172dfeffffdf494e8576f9abab9686dd"}},"metadata":{}},{"name":"stderr","text":"2025-06-19 19:51:22.249950: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750362682.439728      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750362682.491543      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0384f144ced94bcbb747f3ed6e0bb5a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e988112121a4add84db6abfff2f89a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00003.bin:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b30f25fb682e48749d07158490ec5f03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00003.bin:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bb41242235947d1bc96d0c5a524b57a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00003-of-00003.bin:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f041ac97dcf4d1f8a87a40a5c9380a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57c1006bf3c841af892030c7d9a52dee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af6a4ec1c3174b929dc3d7af2148abd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"680ca5dbb8e0431385d6c37e1623c4d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ab4c498f53a407ea489ff74e3087b36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12a654d1bdc048cd80b05fb7b6e87ecc"}},"metadata":{}},{"name":"stdout","text":"Model and Tokenizer loaded successfully!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"pip install -q -U trl peft datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:52:54.305649Z","iopub.execute_input":"2025-06-19T19:52:54.306527Z","iopub.status.idle":"2025-06-19T19:52:59.378265Z","shell.execute_reply.started":"2025-06-19T19:52:54.306503Z","shell.execute_reply":"2025-06-19T19:52:59.377348Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.4/366.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from datasets import Dataset\n\n# Drop rows where the 'Expert' is unknown ('-') as we cannot learn from them.\ndata = data[data['Expert'] != '-'].copy()\n\n# A function to format the data into a prompt\ndef create_prompt(sample):\n    # This format is based on how instruction-tuned models are trained.\n    # <s> and </s> are special tokens for beginning and end of sequence.\n    # [INST] and [/INST] are markers for user instructions.\n    prompt = f\"<s>[INST] Based on the Insurer '{sample['Insurer']}' and Claim Class of Business '{sample['Claim Class of Business']}', which Expert should be recommended? [/INST] The recommended Expert is {sample['Expert']}.</s>\"\n    return {\"text\": prompt}\n\n# Create a Hugging Face Dataset from the pandas DataFrame\ndataset = Dataset.from_pandas(data)\n\n# Apply the formatting function to the dataset\nformatted_dataset = dataset.map(create_prompt)\n\n# Now, 'formatted_dataset' contains a 'text' column with our prompts.\nprint(formatted_dataset[0]['text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:52:59.379319Z","iopub.execute_input":"2025-06-19T19:52:59.379548Z","iopub.status.idle":"2025-06-19T19:53:09.791844Z","shell.execute_reply.started":"2025-06-19T19:52:59.379523Z","shell.execute_reply":"2025-06-19T19:53:09.790944Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/33501 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f71d8dc2cdd54188963cc69d552c0459"}},"metadata":{}},{"name":"stdout","text":"<s>[INST] Based on the Insurer 'Chubb Underwriting Agencies Limited' and Claim Class of Business 'Casualty FinPro', which Expert should be recommended? [/INST] The recommended Expert is Reynolds Porter Chamberlain.</s>\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nfrom trl import SFTTrainer\nfrom datasets import load_dataset\n\n# Set the device\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n\n# Quantization Config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\n# Load Model\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"bitext/Mistral-7B-Insurance\",\n    quantization_config=bnb_config,\n    torch_dtype=torch.bfloat16,\n    device_map='auto'\n)\n\n# Load Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"bitext/Mistral-7B-Insurance\")\ntokenizer.pad_token = tokenizer.eos_token\n\n# Load and Prepare the Dataset\ndataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\ndataset = dataset.select(range(1000))\n\ndef format_instruction(sample):\n    return f\"\"\"### Instruction:\n{sample['instruction']}\n### Response:\n{sample['response']}\"\"\"\n\nformatted_dataset = dataset.map(lambda sample: {'text': format_instruction(sample)})\n\n# Prepare model for k-bit training\nmodel = prepare_model_for_kbit_training(model)\n\n# LoRA Config\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\n# Apply LoRA to the model\nmodel = get_peft_model(model, lora_config)\n\n# Training Arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=4,\n    learning_rate=2e-4,\n    logging_steps=100,\n    num_train_epochs=1,\n    max_steps=500,\n    report_to=\"none\",\n)\n\n# Create the Trainer\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=formatted_dataset,\n    peft_config=lora_config,\n    args=training_args,\n)\n\n# Start the training process\nprint(\"Starting the fine-tuning process...\")\ntrainer.train()\nprint(\"Fine-tuning complete!\")\n\n# Save the trained model adapter\ntrainer.save_model(\"./insurance_recommender_adapter\")\nprint(\"Model adapter saved successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:53:09.792729Z","iopub.execute_input":"2025-06-19T19:53:09.793660Z","iopub.status.idle":"2025-06-19T20:54:58.241567Z","shell.execute_reply.started":"2025-06-19T19:53:09.793632Z","shell.execute_reply":"2025-06-19T20:54:58.240604Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65fbe715c0b8441db217fcdcd8d60c4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/8.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dac21a3cc4d438cb96adb2092800f8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"databricks-dolly-15k.jsonl:   0%|          | 0.00/13.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7641d7076c8644bea94ad5dc03eac5d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/15011 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a21b8620a9134db4885067e9c8e26f02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"568d16f07e394ae887f666dd76dedbe8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b8a4dd4a0574f05908eb004f30e2279"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Adding EOS to train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65cdc81ed8c84b9193e5394154d63b3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51ef971be4cf4320bb49262213e879ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bf708b8b33e4c81bf19dfc64d674bd4"}},"metadata":{}},{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"Starting the fine-tuning process...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [500/500 1:00:55, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>1.668100</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.572100</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.374500</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.270800</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.265000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Fine-tuning complete!\nModel adapter saved successfully.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!zip -r my_trained_model.zip /kaggle/working/insurance_recommender_adapter /kaggle/working/results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T21:37:21.378396Z","iopub.execute_input":"2025-06-19T21:37:21.378748Z","iopub.status.idle":"2025-06-19T21:37:33.102737Z","shell.execute_reply.started":"2025-06-19T21:37:21.378720Z","shell.execute_reply":"2025-06-19T21:37:33.101914Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/insurance_recommender_adapter/ (stored 0%)\n  adding: kaggle/working/insurance_recommender_adapter/adapter_config.json (deflated 55%)\n  adding: kaggle/working/insurance_recommender_adapter/tokenizer_config.json (deflated 68%)\n  adding: kaggle/working/insurance_recommender_adapter/special_tokens_map.json (deflated 79%)\n  adding: kaggle/working/insurance_recommender_adapter/adapter_model.safetensors","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 8%)\n  adding: kaggle/working/insurance_recommender_adapter/tokenizer.model (deflated 55%)\n  adding: kaggle/working/insurance_recommender_adapter/README.md (deflated 66%)\n  adding: kaggle/working/insurance_recommender_adapter/tokenizer.json (deflated 85%)\n  adding: kaggle/working/insurance_recommender_adapter/training_args.bin (deflated 51%)\n  adding: kaggle/working/results/ (stored 0%)\n  adding: kaggle/working/results/checkpoint-500/ (stored 0%)\n  adding: kaggle/working/results/checkpoint-500/adapter_config.json (deflated 55%)\n  adding: kaggle/working/results/checkpoint-500/tokenizer_config.json (deflated 68%)\n  adding: kaggle/working/results/checkpoint-500/special_tokens_map.json (deflated 79%)\n  adding: kaggle/working/results/checkpoint-500/scheduler.pt (deflated 56%)\n  adding: kaggle/working/results/checkpoint-500/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/results/checkpoint-500/tokenizer.model (deflated 55%)\n  adding: kaggle/working/results/checkpoint-500/trainer_state.json (deflated 66%)\n  adding: kaggle/working/results/checkpoint-500/README.md (deflated 66%)\n  adding: kaggle/working/results/checkpoint-500/tokenizer.json (deflated 85%)\n  adding: kaggle/working/results/checkpoint-500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/results/checkpoint-500/training_args.bin (deflated 51%)\n  adding: kaggle/working/results/checkpoint-500/optimizer.pt (deflated 9%)\n","output_type":"stream"}],"execution_count":15}]}